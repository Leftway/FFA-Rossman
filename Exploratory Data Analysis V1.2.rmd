---
title: "Rossman Store Sales "
subtitle: "Group 1 - Exploratory Data Analysis"
author: '1. Kang Jun Han Brandon,  2.Kenny Sim Jun Hong, 3. Lim Yong Chuan,  4. Tan Soon Wei,  5. Teo Xiangquan Martin'
date: "`r Sys.Date()`"
output: html_document
---
```{r libraries, include = F}
# Install & load relevant libraries. 
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, 
               ggplot2,
               lubridate, 
               plotly,
               mice,
               kableExtra,
               zoo,
               plotly,
               Scale,
               forecast,
               rpart,
               caret,
               e1071)
              
# Create html_df for later stlying
html_df <- function(x){
  kable(x) %>%
   kable_styling(bootstrap_options = "striped", full_width = F, position = "left")}

```

# Import files
``` {r Import, eval = T}
# Import train.csv, test.csv and store.csv
train <- read.csv("train.csv", stringsAsFactors = F)
test <- read.csv("test.csv", stringsAsFactors = F)
store <- read.csv("store.csv", stringsAsFactors = F)
```

# Data Cleaning 
## 1. Data Structure
```{r Dimensions Check, include = F}
 str(train)
 str(test)
 str(store)
 dim(train)
 dim(test)
 dim(store)
```

```{r Data Structure, eval = T, echo = F}
# Rows and columns of each file
matrix(c("1017209", "9", "41088", "8", "1115", "10"),ncol=2, byrow= TRUE)%>% as.data.frame() %>% `row.names<-`(c("Train", "Test", "Store")) %>% `colnames<-`(c("No. of Rows", "No. of Columns")) %>% html_df
```

###   1.1 Convert data types
+ Insert explanation for the type conversion here
``` {r Converting data, eval = T}
#a. Train
train <- train %>% mutate(
  DayOfWeek                 = as.factor(DayOfWeek),
  Date                      = as.Date(Date),
  Open                      = as.factor(Open),
  Promo                     = as.factor(Promo), 
  StateHoliday              = as.factor(StateHoliday),   # Has 4 values!
  SchoolHoliday             = as.factor(SchoolHoliday))

str(train)

#b. Test
test <- test %>% mutate(
  DayOfWeek                 = as.factor(DayOfWeek),
  Date                      = as.Date(Date),
  Open                      = as.factor(Open),
  Promo                     = as.factor(Promo),
  StateHoliday              = as.factor(StateHoliday),   # Only 2 values! What're the state holidays?
  SchoolHoliday             = as.factor(SchoolHoliday))
 str(test)

#c. Store
store <- store %>% mutate(
  StoreType                 = as.factor(StoreType),
  Assortment                = as.factor(Assortment),
  Promo2                    = as.factor(Promo2),
  PromoInterval             = as.factor(PromoInterval),
  CompetitionOpenSinceMonth = as.numeric(CompetitionOpenSinceMonth),
  CompetitionOpenSinceYear  = as.numeric(CompetitionOpenSinceYear))
str(store)

```


## 2. Check and impute values for NA
###   2.1 Train and Test

*Train set*
```{r NA values - train, eval = T, echo = F}
# Train
train %>% is.na() %>% colSums() %>% data.frame() %>% `colnames<-`("No. of NAs") %>% html_df
```

*Test set*
```{r NA values - test, eval = T, echo = F}
# Test 
test %>% is.na() %>% colSums() %>% data.frame() %>% `colnames<-`("No. of NAs") %>% html_df %>% row_spec(5, bold = T, color = "red")
```
_Observations_:

+ In the test set, variable 'Open' should have only two possible values (Open = 1 or Closed = 0), so the 11 NA's should be changed to either 1 or 0.
+ If Open is = 1, but we assume = 0, the error score will increase because of misprediction.
+ If Open is = 0, but we assume = 1, then there's no penalty in scoring as closed stores with 0 sales are not considered in scoring. 

Hence, we will impute 1, using the replace() function, into the NA values for the 'Open' variable in the test dataset. 

#### Test - Impute values for Open = NA
``` {r NA Impute: Open, eval = T, echo = F}
# a. Impute NA with Open = 1
test <- test %>% mutate(Open = replace(Open, is.na(Open),1))

# b. Check if NA has been replaced:
test %>% is.na() %>% colSums() %>% data.frame() %>% `colnames<-`("No. of NAs") %>% html_df %>% row_spec(5, bold = T, color = "red")
```

###   2.2 Store  
```{r NA values - Store, eval = T, echo = F}
# Store
store %>% is.na() %>% colSums() %>% data.frame() %>% `colnames<-`("No. of NAs") %>% html_df
```

#### Store - Impute values for CompetitionDistance
With mean
```{r NA impute: CompetitionDistance, eval = T}
# Impute NA with mean of CompetitionDistance 
store <- store %>% 
  mutate(CompetitionDistance= replace(CompetitionDistance, is.na(CompetitionDistance), mean(CompetitionDistance,na.rm=T)))
          
# Check for NAs
store %>% filter(is.na(CompetitionDistance)) %>% nrow() 

```



#### V1_Store - Impute values for CompetitionOpenSince and Promo2Since
use median
```{r NA impute: CompetitionOpenSince + Promo2Since, eval = T, echo = T}
# Impute NA with median   
store <- store %>%
          mutate(CompetitionOpenSinceMonth=ifelse(is.na(CompetitionOpenSinceMonth),median(CompetitionOpenSinceMonth,na.rm=T), CompetitionOpenSinceMonth),
                 CompetitionOpenSinceYear=ifelse(is.na(CompetitionOpenSinceYear),median(CompetitionOpenSinceYear,na.rm=T), CompetitionOpenSinceYear),
                 Promo2SinceYear=ifelse(is.na(Promo2SinceYear),0, Promo2SinceYear),
                 Promo2SinceWeek=ifelse(is.na(Promo2SinceWeek),0, Promo2SinceWeek))

# Last check for NAs
store %>% is.na() %>% colSums() %>% data.frame() %>% `colnames<-`("No. of NAs") %>% html_df %>%
  row_spec(c(4,5,6,8,9), bold = T, color = "red")
```


#### V2_Store - Impute values for CompetitionOpenSince and Promo2Since
use MICE package
```{r NA impute: CompetitionOpenSince + Promo2Since, eval = T, echo = T}
# Initialize mice algorithm where it use information from other variables in the dataset to predict and impute the missing values

init = mice(store, maxit = 0) 
meth = init$method
predM = init$predictorMatrix

# Store ID variable does not have any predictive value, Select the BMI variable to not be included as predictor during imputation
predM[, c("Store")] = 0

# Specify methods for inputing values
meth[c("CompetitionOpenSinceMonth")]="norm"
meth[c("CompetitionOpenSinceYear")]="norm"
meth[c("Promo2SinceWeek")]="norm"
meth[c("Promo2SinceYear")]="norm"

# Run multiple imputation
set.seed(111)
imputed = mice(store, method=meth, predictorMatrix=predM, m=10)

# Replace store with inputed missing value dataset
store <- complete(imputed)
store$CompetitionOpenSinceMonth <- round(store$CompetitionOpenSinceMonth, digits = 0)
store$CompetitionOpenSinceYear <- round(store$CompetitionOpenSinceYear, digits = 0)
store$Promo2SinceWeek <- round(store$Promo2SinceWeek, digits = 0)
store$Promo2SinceYear <- round(store$Promo2SinceYear, digits = 0)

store <- store %>%
          mutate(CompetitionOpenSinceMonth = replace(CompetitionOpenSinceMonth, CompetitionOpenSinceMonth<1, 1),
                 CompetitionOpenSinceMonth = replace(CompetitionOpenSinceMonth, CompetitionOpenSinceMonth>12, 12),
                 CompetitionOpenSinceYear = replace(CompetitionOpenSinceYear, CompetitionOpenSinceYear>2015, 2015),
                 Promo2SinceWeek = replace(Promo2SinceWeek, Promo2SinceWeek<1, 1),
                 Promo2SinceWeek = replace(Promo2SinceWeek, Promo2SinceWeek>50, 50),
                 Promo2SinceYear = replace(Promo2SinceYear, Promo2SinceYear<2009, 2009),
                 Promo2SinceYear = replace(Promo2SinceYear, Promo2SinceYear>2015, 2015)
                 )

# Last check for NAs
store %>% is.na() %>% colSums() %>% data.frame() %>% `colnames<-`("No. of NAs") %>% html_df %>%
  row_spec(c(4,5,6,8,9), bold = T, color = "red")
```

## 3. Completeness Check - Dates 
```{r Overall Dates Check, eval = T, echo = F }
plot(train$Date, type = "l") 
plot(test$Date, type = "l") 
```

No visible breaks in data, hence no missing data by date.

```{r Stores + Date, eval = F }
## Find missing data ##

# Expected rows of records (1115 x 941 days) = 1,049,215  vs Actual = 1,017,209. Missing records = 33,121

# 1. Finding all combinations of stores and dates
allStoresAndDates <- expand.grid(unique(train.store$Store), unique(train.store$Date))
# Explanation
 # - List all permutations of stores (1,115) and dates (971 days) 


# 2. Naming the two columns in the newly created dataframe for step 3
names(allStoresAndDates) <- c("Store", "Date")


# 3. Extract stores with missing dates and consequently sales data.
missingDatesForStores <-  anti_join(allStoresAndDates, train.store, by = c("Store", "Date"))
# Explanation
  # - anti_join is a dplyr function that finds unmatched records.
  # - 1st parameter = "Master table"
  # - 2nd parameter = Comparison table
  # - Function checks "train.store" records against "allStoresAndDates" and for 
  # records that train.store do not have, show it as an output.
# Actual missing records do not equate to expected missing records as some stores may only be opened after the start date.


## Note: Ignoring missing data ##
# As per competition host, Florian, "The missing data you’re observing for a 6 month period in 2014 was a mistake done by us. For some stores this data was simply not included in the train-set. We’ve discussed this with Kaggle and decided that it’s an insignificant omission as there are still more than enough store/date combinations left to create a model on.""

## Conclusion: Proceed to find other missing data.

```


# Exploratory Data Analysis
## Data Merging 
```{r Merging , eval = T}
train.store <- merge(train, store, by = "Store")
test.store <- merge(test, store, by = "Store")

```

## 1. Day of week 
Sunday has the least sales for all opened stores over the data period, and that could be because most stores are closed on Sundays. 
```{r Sales - DayofWeek, eval = T }
# Check if closed stores have any sales. Result = no anomalies.
train.closed <- train[train$Open == 0,]
train.closed$Sales %>% sum()  

# First plot
ggplot(data = train, aes (x= DayOfWeek, y= Sales)) +
geom_bar(stat = "identity")

# Second plot
train %>% group_by(DayOfWeek, Open) %>% tally() %>%
  ggplot(aes(x=DayOfWeek, y=n, fill = Open)) +
  geom_bar(stat="identity")

```

## 2. PromotionInterval, StoreType, Assortment Analysis 
```{r ProInt + Type + Assortment, eval = T}
# PromotionInterval
ggplot(train.store, aes(x = factor(PromoInterval), y = Sales, color = PromoInterval)) +
    geom_col() +
    ggtitle("Sales by PromoInterval")

# StoreType
ggplot(train.store, aes(x = Date, y = Sales, color = StoreType))+ 
    geom_smooth(se= F, size = 1.5) +
    ggtitle("Sales by StoreType")


ggplot(train.store, aes(x = Date, y = Customers, color = StoreType)) + 
    geom_smooth(se= F, size = 1.5) +
    ggtitle("Customers by StoreType")

# Assortment
ggplot(train.store, aes(x = Date, y = Sales, color = Assortment)) + 
    geom_smooth(se= F, size = 1.5) +
    ggtitle("Sales by Assortment")

    
ggplot(train.store, aes(x = Date, y = Customers, color = Assortment)) + 
    geom_smooth(se= F, size = 1.5) +
    ggtitle("Customers by Assortment")
```
## 3. CompetitionDistance, OpenSinceMonth/Year
```{r Competition, eval = T}
# Combine year and month into one date variable:
store$CompetitionOpenSince <-as.yearmon(paste(store$CompetitionOpenSinceYear, 
                                               store$CompetitionOpenSinceMonth, sep = "-"))

# P.S: yearmon functon creates a numeric vector interpreted in "years" and fractions of years. e.g. 1961.5 = June 1961.

# Histogram for CompetitionOpenedSince
plot_ly(x= store$CompetitionOpenSince, type = "histogram") %>%
layout(title = "Distribution of CompetitionOpenedSince",
         xaxis = list(title = "Year",
                      zeroline = FALSE),
         yaxis = list(title = "Count",
                      zeroline = FALSE))
```
_Observations_: Many competitors opened recently, except 1 that opened in 1900 and 1 in 1961. 

## 4. Promo2, Promo2Since Week/Year
```{r Promo2 + Since Week/Year, eval = T}
# Combine year and month into one date variable:
store$Promo2Since <- as.POSIXct(paste(store$Promo2SinceYear, 
                                   store$Promo2SinceWeek, 1, sep = "-"),
                             format = "%Y-%U-%u")

hist(as.numeric(as.POSIXct("2015-10-01", format = "%Y-%m-%d") - store$Promo2Since), 
     100, main = "Days since start of promo2")

# Histogram for Promo2Since (in days)
plot_ly(x= as.POSIXct("2015-10-01", format = "%Y-%m-%d") - store$Promo2Since, type = "histogram") %>%
layout(title = "Distribution of Promo2Since",
         xaxis = list(title = "Days",
                      zeroline = FALSE),
         yaxis = list(title = "Count",
                      zeroline = FALSE))
```

## 5. Competition Distance

```{r Competiton Distance, eval = T}
# MeanSales by CompetitionDistance
salesbydist <- train.store %>% group_by(CompetitionDistance) %>% summarise(MeanSales = mean(Sales, na.rm=TRUE))

## NOTE: Plotting without mean makes everthing too cluttered. Code below can't see shit. Followed online guide.
## ggplot(train.store, aes(x = CompetitionDistance, y = Sales)) + geom_point() + geom_smooth() 

# salesbydist scatterplot 

ggplot(salesbydist, aes(x = CompetitionDistance, y = MeanSales)) + 
    geom_point() + geom_smooth() + scale_x_log10() + scale_y_log10()

```
__Observations__: 
Interestingly, stores with competition that are closer have slightly higher sales on average while those with competition that are further have slightly lower sales. Just based on this graph alone, we cannot deduce much, but a possibility is that the stores with close competitors are situated in areas with high footfall such as cities, contributing to slightly higher revenue. 

```{r Merge: Store(new) + Training, eval = T}
train.store <- merge(train, store, by = "Store")

train.store2 <- train.store %>% dplyr:: select(
  DayOfWeek, #1
  Sales,     #2
  Customers, #3
  Open,      #4
  Promo,     #5
  StateHoliday, #6
  SchoolHoliday, #7 
  StoreType,   #8
  Assortment,  #9
  CompetitionDistance,  #10
  Promo2,               #11
  PromoInterval,        #12
  CompetitionOpenSince) #13
  #Promo2Since)          #14
str(train.store2)

```

# Models creation
## 1. Using step-wise regression to select best variables 
```{r Features selection: Stepwise, eval = F }

# Run lm first
train.mlm <- lm(Sales ~.,  data = train.store2)
str(train.store)

# Ultimate step-wise regression...is useless in feature selection here...
training.swr <- step(train.mlm, direction = "both")
summary(training.swr) 

```
_Observation_: All variables are significant with stepwise regression. Proceed to classification trees for prediction

## 2. Using decision trees to predict sales
```{r Decision Trees, eval = F }

# Decision Tree with Rpart function
train.dt <- rpart(Sales ~., data = train.store2, control = rpart.control(cp = 0.0001))

# Choosing the best cp (complexity parameter)
bestcp <- train.dt$cptable[which.min(train.dt$cptable[,"xerror"]),"CP"]
train.dt.pruned <- prune(train.dt, cp = bestcp)

# Confusion matrix
conf.matrix <- table(train.dt.pruned$Sales, predict(train.dt.pruned, na.action = na.pass))

rownames(conf.matrix) <- paste("Actual", rownames(conf.matrix), sep = ":")
colnames(conf.matrix) <- paste("Pred", colnames(conf.matrix), sep = ":")
print(conf.matrix)

# Use training data to predict and assess performance of  model
Train.predict <- predict(train.dt.pruned, train.store2, type = "matrix")     
  
confusionMatrix(table(Train.predict, train.store2$Sales),positive = "1")



```



          
