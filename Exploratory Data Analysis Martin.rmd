---
title: "Rossman Store Sales "
subtitle: "Group 1 - Exploratory Data Analysis"
author: '1. Kang Jun Han Brandon, 2.Kenny Sim Jun Hong, 3. Lim Yong Chuan,  4. Tan Soon Wei,  5. Teo Xiangquan Martin'
date: "`r Sys.Date()`"
output:
  tufte::tufte_html: 
    tufte_variant: "default"
    self_contained: yes
---
```{r libraries, include = F}
# Install & load relevant libraries. 
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, 
               ggplot2,
               lubridate, 
               plotly,
               kableExtra,
               Knitr,
               dplyr)

# Create html_df for later stlying
html_df <- function(x){
  kable(x) %>%
   kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
}
```

# Importing and cleaning data
## 1. Import files
``` {r Import, eval = T}
# Import train.csv, test.csv and store.csv
train <- read.csv("train.csv", stringsAsFactors = F)
test <- read.csv("test.csv", stringsAsFactors = F)
store <- read.csv("store.csv", stringsAsFactors = F)
```

## 2. Data Structure
```{r Dimensions Check, include = F}
 str(train)
 str(test)
 str(store)
 dim(train)
 dim(test)
 dim(store)
```
 
```{r Data Structure, eval = T, echo= F }
# Rows and columns of each file
matrix(c("1017209", "9", "41088", "8", "1115", "10"),ncol=2, byrow= TRUE)%>% as.data.frame() %>% `row.names<-`(c("Train", "Test", "Store")) %>% `colnames<-`(c("No. of Rows", "No. of Columns")) %>% html_df
```

## 3. Check for NA 
### NA values for train ###   
```{r NA values - train, eval = T, echo = F}
# Train 
train %>% is.na() %>% colSums() %>% data.frame() %>% `colnames<-`("No. of NAs") %>% html_df
```


### NA values for test ###   
``` {r NA values - test, eval = T, echo = F}
# Test 
test %>% is.na() %>% colSums() %>% data.frame() %>% `colnames<-`("No. of NAs") %>% html_df %>% row_spec(5, bold = T, color = "red")
```


_Observations_:

+ Variable 'Open' should have only two possible values (Open = 1 or Closed = 0), so the 11 NA's should be changed to either 1 or 0.
+ If Open is = 1, but we assume = 0, the error score will increase because of misprediction.
+ If Open is = 0, but we assume = 1, then there's no penalty in scoring as closed stores with 0 sales are not considered in scoring. 

Hence, we will impute 1 into the NA values for the 'Open' variable in the test dataset. 

### NA values for store ###   
```{r NA values - Store, eval = T, echo = F}
# Store
store %>% is.na() %>% colSums() %>% data.frame() %>% `colnames<-`("No. of NAs") %>% html_df
```



## 4. Imputing missing values for test
``` {r Impute, eval = T}
# a. Retrieve records with Open = NA
test %>% filter(is.na(Open)) %>% html_df()

# b. Replace NA with Open = 1
test <- test %>% mutate(Open = replace(Open, is.na(Open),1))

# c. Check if NA has been replaced:
sum(is.na(test$Open))
```



## 5. Convert data types

+ Insert explanation for the type conversion here

``` {r Converting data, eval = T}
#a. Train
train <- train %>% mutate(
  DayOfWeek                 = as.factor(DayOfWeek),
  Date                      = as.Date(Date),
  Open                      = as.factor(Open),
  Promo                     = as.factor(Promo), 
  StateHoliday              = as.factor(StateHoliday),   # Has 4 values!
  SchoolHoliday             = as.factor(SchoolHoliday),
  Day                       = as.integer(format(train$Date, "%d")), # New variable 1
  Month                     = as.integer(format(train$Date, "%m")), # New variable 2
  Year                      = as.integer(format(train$Date, "%Y"))) # New variable 3
str(train)

#b. Test
test <- test %>% mutate(
  DayOfWeek                 = as.factor(DayOfWeek),
  Date                      = as.Date(Date),
  Open                      = as.factor(Open),
  Promo                     = as.factor(Promo),
  StateHoliday              = as.factor(StateHoliday),   # Only 2 values! What're the state holidays?
  SchoolHoliday             = as.factor(SchoolHoliday),
  Day                       = as.integer(format(test$Date, "%d")),  # New variable 1
  Month                     = as.integer(format(test$Date, "%m")),  # New variable 2
  Year                      = as.integer(format(test$Date, "%Y")))  # New variable 3
str(test)

#c. Store
store <- store %>% mutate(
  StoreType                 = as.factor(StoreType),
  Assortment                = as.factor(Assortment),
  Promo2                    = as.factor(Promo2))
str(store)

```


# Exploratory Data Analysis
## 1. Dates
Sales data start from `r min(train$Date)` to `r max(train$Date)`, which spans a total of `r max(train$Date) - min(train$Date)` days or 2 years 7 months.

## 2. Sales - By day of week (Dependent Variable)

__Observations__:
Why are Sunday's sales so low? To check further
```{r Sales - DayofWeek, eval = T }
ggplot(data = train, aes (x= DayOfWeek, y= Sales)) +
geom_bar(stat = "identity")

count <- train %>%   count(DayOfWeek, sort = T)
count
unique(train$DayOfWeek)

```
## 3

## Reserved . Skewedness of data
```{r, eval = T}
#group revenues by quarter


train <- train %>% 
          group_by(Store,year,week) %>%
          mutate(sales.wk = sum(Sales,na.rm = TRUE)) %>%
          ungroup() %>%
          arrange(Store,year,week)

train.wk <- distinct(train[,c("Store","year","week","sales.wk")])

train.wk <- 
  train.wk %>%
  group_by(Store,year) %>%
  mutate(
         sales.wk_gr = sales.wk / lag(sales.wk) - 1,   
         sales.wk_mom = sales.wk / lag(sales.wk, 4) - 1,
         sales.wk_d = sales.wk - lag(sales.wk)
         ) %>%
  ungroup()

sales.wk_plot <- ggplot(data = train.wk,
            mapping = aes(x = sales.wk))
sales.wk_plot + geom_density()

sales.wk_gr_plot <- ggplot(data = train.wk,
            mapping = aes(x = sales.wk_gr))
sales.wk_gr_plot + geom_density()

sales.wk_mom_plot <- ggplot(data = train.wk,
            mapping = aes(x = sales.wk_mom))
sales.wk_mom_plot + geom_density()

sales.wk_d_plot <- ggplot(data = train.wk,
            mapping = aes(x = sales.wk_d))
sales.wk_d_plot + geom_density()



train.dy <- 
  train %>%
  group_by(Store,Date)
  mutate(
         sales.dy_gr = Sales / lag(Sales) - 1,   
         sales.dy_wow = Sales / lag(Sales, 7) - 1,
         sales.wk_d = sales.wk - lag(sales.wk)
         sales.wk_yoy = sales.wk - lag(sales.wk)
         ) %>%
  ungroup()

sales.wk_plot <- ggplot(data = train.wk,
            mapping = aes(x = sales.wk))
sales.wk_plot + geom_density()

sales.wk_gr_plot <- ggplot(data = train.wk,
            mapping = aes(x = sales.wk_gr))
sales.wk_gr_plot + geom_density()

sales.wk_mom_plot <- ggplot(data = train.wk,
            mapping = aes(x = sales.wk_mom))
sales.wk_mom_plot + geom_density()

sales.wk_d_plot <- ggplot(data = train.wk,
            mapping = aes(x = sales.wk_d))
sales.wk_d_plot + geom_density()





counttotal <- test[,c("Store","Id")]
counttotal %>%
  group_by(Store) %>%
  summarise(count = n_distinct(Id))

train <- train %>%
          mutate(week = week(as.Date(Date)), year = year(as.Date(Date)))

test <- test %>%
          mutate(week = week(as.Date(Date)), year = year(as.Date(Date)))

week_day <- c(train$week, train$DayOfWeek)
week_day <- unique(week_day)
week_day <- data.frame(id=week_day)
week_day$week_day <- factor(week_day$id)



#cleaning of missing data in store.csv
store <- store %>%
          mutate(CompetitionOpenSinceMonth=ifelse(is.na(CompetitionOpenSinceMonth),median(CompetitionOpenSinceMonth,na.rm=T), CompetitionOpenSinceMonth),
                 CompetitionOpenSinceYear=ifelse(is.na(CompetitionOpenSinceYear),median(CompetitionOpenSinceYear,na.rm=T), CompetitionOpenSinceYear),
                 Promo2SinceYear=ifelse(is.na(Promo2SinceYear),0, Promo2SinceYear),
                 Promo2SinceWeek=ifelse(is.na(Promo2SinceWeek),0, Promo2SinceWeek))


train.df <- merge(train, store, by = "Store")
#calculate average sales by store-type-assort
train.df <- train.df %>% 
            group_by(Store, StoreType, Assortment) %>%
            mutate(store_avg=mean(Sales, rm.na=T)) %>%
            ungroup()

#select the first average sales data for each store-type-assort
train.avg.df <- train.df %>%
  group_by(Store, StoreType, Assortment) %>%
  slice(1) %>%
  select(Store,StoreType,Assortment,store_avg) %>%
  ungroup()

train.test <- left_join(test, train.avg.df)

#calculate multipliers based on store_avg (and removing NaN and Inf)
train.df$Daily_mult <- train.df$Sales / train.df$store_avg
train.df[!is.finite(train.df$Daily_mult),]$Daily_mult <- NA

#calculate mean by daily-store-storetype-assort and distribute to train.test
train.df <- train.df %>%
  group_by(Store,StoreType,Assortment,week,DayOfWeek) %>%
  mutate(naive_mean=mean(Sales, rm.na=T)) %>%
  ungroup()

train_wm <- train.df %>%
  group_by(Store,StoreType,Assortment,week,DayOfWeek) %>%
  slice(1) %>%
  ungroup() %>%
  select(Store,StoreType,Assortment,week,DayOfWeek,naive_mean)

train.test <- train.test %>% arrange(Store,StoreType,Assortment,week,DayOfWeek)
train.test <- left_join(train.test,train_wm)

#all the ids are available in training data
table(is.na(train.test$naive_mean))
table(is.na(train$Date))

train.df %>%
  group_by(DayOfWeek, Store) %>%
  mutate(sales=mean(Sales)) %>%
  slice(1) %>%
  ungroup() %>%
  ggplot(aes(y=Sales, x=DayOfWeek, color=factor(Store))) +
  geom_line() + xlab("Day") + ylab("Sales for Store (StoreType,Assortment)") +
  theme(legend.position = "none")
```
          
